# Характеристики временной области

_Скорость пересечения нуля (ZCR)_: 
ZCR звукового кадра определяется как скорость изменения знака сигнала в течение кадра. Математически это число раз, когда сигнал меняет свой знак с положительного на отрицательный и наоборот, деленный на длину кадра. Проще говоря, ZCR – это количество раз, когда сигнал пересекает нулевой уровень в течение одной секунды. ZCR для i-го кадра с длиной N определяется формулой (1) как:

\begin{equation}
\tag{1}
Z(i) = \frac{1}{2N}\sum{|sgn[x_i(n)] - sgn[x_i(n-1)]|}
\end{equation}

ZCR – очень эффективный способ обнаружения голосовой активности, который определяет, является ли речевой кадр голосовым, невокализованным или беззвучным.

На @fig:ZCR1 показан пример ZCR с речевым сигналом, а на @fig:ZCR2 с музыкальным сигналом.

![ZCR с речевым сигналом.](ZCR1.png){#fig:ZCR1}

![ZCR с музыкальным сигналом.](ZCR2.png){#fig:ZCR2}

ZCR – это также метод оценки основной частоты (FF) @kedem1986spectral речи. ZCR равен удвоенной частоте сигнала. Следовательно, можно сказать, что ZCR дает косвенную информацию о частоте сигнала. А значит, что эта функция может быть использована для разработки дискриминатора и классификатора @saunders1996real. Псевдокод MATLAB для расчета ZCR приведен ниже:

| _Алгоритм 1_: ZCR                                                                                                                                              |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. **Результат**: скорость пересечения нуля сигнала <br/>2. Инициализация: одноканальный сигнал x_i (n)<br/>3. $ZCR=sum(abs(diff(x_i (n)>0)))/length(x_i (n))$ |



_Методы на основе амплитуды_: они основаны на очень простом анализе временной огибающей сигнала. Различные типы функций на основе амплитуды обсуждаются ниже:

_Дескриптор амплитуды (AD)_: эта функция помогает различать звуковые огибающие различного типа, учитывая мощность, изменение длительности сегментов сигнала от высоких и низких амплитуд с помощью адаптивного порога. Эта функция в основном используется в классификации звуков окружающей среды @mitrovic2006discrimination.

_Атака, Спад, Задержка, Затухание (ADSR)_: эта функция ADSR используется при анализе музыки и классификации музыкальных жанров.

Функция огибающей ADSR, которая показана на @fig:ADSR недостижима для большинства звуков реального времени, потому что часть спада отсутствует, часть задержки отсутствует в речевых и звуках окружающей среды (присутствует только в звуках музыки). Для решения такой проблемы используется модифицированная огибающая, основанная на атаке и затухании, она называется AR-огибающей и показана на @fig:AR. В нем часть спада отсутствует, а часть задержки и затухания объединена. Огибающие ADSR и AR используются в тембровом анализе музыкальных инструментов @burred2009dynamic. Псевдокод MATLAB для огибающей ADSR приведен в алгоритме 2.

![Огибающая ADSR.](ADSR.png){#fig:ADSR}

![Огибающая AR.](AR.png){#fig:AR}

| _Алгоритм 2_                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. **Результат**: огибающая ADSR<br/>2. Вход: номер музыкальной клавиши, длительность нажатия.<br/>3. $freq=440*2(((keynum-49))/12)$ вычисляет частоту нажатой клавиши<br/>4. $t=0∶ 1$ (частота дискретизации : длительность)<br/>5. $tone=sin(2*pi*freq*t)$ генерирует синусоидальный выходной тон<br/>6. $A=linspace(0,1,0,1*(length(tone))$ повышение 10% сигнала<br/>7. $A=linspace(1,0.8,0.15*(length(tone))$ падение 15% сигнала<br/>8. $A=linspace(0.8,0.8,0,6*(length(tone))$ задержка 60% сигнала<br/>9. $A=linspace(0.8,0,0.15*(length(tone))$ падение 15% сигнала<br/>10. $ADSR= [ADSR]$<br/>11. Умножить $ADSR$ и $tone$. |

_Логарифм времени атаки (LAT)_: это логарифм (с основанием 10) промежутка времени между началом времени и временем достижения его стабильной части. Он был использован для обнаружения музыкального начала @smith2010musical и распознавания окружающего звука @muhammad2009environment,@valero2010applicability.

| _Алгоритм 3_                                                                                                   |
|----------------------------------------------------------------------------------------------------------------|
| 1. **Результат**: Логарифм времени атаки<br/>2. $LAT=\log_{10} (t_{attackend}-t_{attackstart})$ где t – время. |

_Shimmer_: вычисляет циклические изменения амплитуды в форме волны. Он используется для обнаружения голосовой активности, распознавания говорящего, проверки говорящего @farrus2007jitter, классификации музыкальных звуков @jensen1999pitch.

_Методы на основе энергии_:

_Кратковременная энергия (STE)_: звуковые сигналы носят нестационарный характер. Нестационарный сигнал может быть преобразован в небольшие части квазистационарных сигналов с использованием метода кадрирования / формирования окон. Энергия на выходе сигнала является переменной и, следовательно, невозможно предсказать ее значение. Для этого рассчитывается энергия короткого времени, которая является энергией из кадра. STE @al-shoshan определяется как средняя энергия на кадр. STE является низким для невокализованных сегментов и высоким для вокализованных сегментов. На @fig:STE1 показан STE для речевого сигнала, а на @fig:STE2 для музыкального сигнала. STE используется для обнаружения вокализованных и невокализованных сегментов @yang2010comparative, обнаружения появления музыки @smith2010musical, обнаружения звука окружающей среды @peltonen2002computational, обнаружения и анализа гласных @korkmaz2019turkish и систем наблюдения на основе звука @rabaoui2008using. Псевдокод для расчета STE приведен в алгоритме 4.

![STE для разговора.](STE1.png){#fig:STE1}

![STE для музыки.](STE2.png){#fig:STE2}

| _Алгоритм 4_                                                                                                                                                                                                                                      |
|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. **Результат**: Значение кратковременной энергии<br/>2. Вход: Звуковой сигнал $(x)$, тип окна, амплитуда и длинна.<br/>3. $win=$ выбор оконной функции<br/>4. $xnew= x^2$<br/>5. $STE= xnew \bigotimes win$ свертка окна и сигнального квадрата |

_Громкость_: громкость звука - одна из самых многообещающих функций слуховой системы человека. Математически громкость определяется как среднеквадратичное значение (RMS) величины сигнала в кадре. Оно используется в распознавании речи / музыки @fu2010survey, сегментации речи и классификации акустических сцен @jiang2005svm. Алгоритм 5 поясняет псевдокод для расчета громкости аудио сигнала.

| _Алгоритм 5_                                                                                                                                                                     |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. **Результат**: Громкость аудио сигнала<br/>2. Вход: Звуковой сигнал $(x)$, частота дискретизации $(Fs)$<br/>3. $loudness=integratedLoudness(x,Fs)$ встроенная функция MATLAB. |

_Временной центроид (TC)_: Временной центроид – это время, усредненное по энергетической огибающей. Временной центроид был использован для распознавания звука в окружающей среде @yang2010comparative и классификации акустических сцен @fu2010survey. Алгоритм ТС приведен ниже:

| _Алгоритм 6_                                                                                                                                                                                                               |
|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 1. Результат: TC<br/>2. $find\, e(x)=$ энергетическая огибающая сигнала<br/>3. Умножение $e(x)$ на сам сигнал.<br/>4. Найти сумму огибающей и энергии сигнала<br/>5. $TC=$ Разделить результат на общую энергию огибающей. |

_Методы, основанные на автокорреляции_: автокорреляция – это мера самоподобия сигнала во временной области. Проще говоря, он измеряет сходство между сигналом и его задержанной версией. Значение автокорреляции +1 представляет сильную положительную ассоциацию, –1 представляет отрицательную ассоциацию и 0 показывает отсутствие ассоциации. Автокорреляция при нулевой задержке всегда равна 1, потому что сигнал всегда идеально коррелирует с самим собой. На @fig:AUTO показаны значения автокорреляции речевого сигнала с самим собой с временной задержкой 20 с. Например, для временной задержки 1 значение автокорреляции равно 0,8, что представляет 80%-ое сходство сигнала с самим собой @jiang2005svm,@peeters2004large.
Функция автокорреляции используется для определения периодичности, присутствующей в сигнале. Он используется для анализа музыкальных ритмов и их темпа. Он также используется для оценки основного тона (основной частоты) сигнала.

![Значения автокорреляции сигнала с задержкой 20.](AUTO.png){#fig:AUTO}

_Основанные на ритме_: Ритм в целом – это регулярное повторение паттерна во времени. Ритм находится в музыкальных инструментах, поэзии (речи) и звуках окружающей среды (например, щебетание птиц). Некоторые особенности ритма: длительность речи, частота артикуляции, длительность фонемы, отношение паузы, общая длительность, общая длительность паузы, общая длительность гласного, метрика импульса, четкость импульса, периодичность полосы, трекер ритма, гистограмма ритма и т. Д. Метрика импульса является мерой, которая использует длительную автокорреляцию полосы пропускания в течение 5 с. Эта функция используется в различении речи / музыки @ando2013autocorrelation,@rabaoui2008using, анализе патологической речи @el2000speech, классификации музыкальных жанров @tzanetakis2002musical, классификации музыкальных инструментов.